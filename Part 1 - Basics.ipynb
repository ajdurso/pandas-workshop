{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Pandas\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is the essential data analysis library for Python programmers. It provides fast and flexible data structures built on top of [numpy](http://www.numpy.org/).\n",
    "\n",
    "It is well suited to handle \"tabular\" data (that might be found in a spreadsheet), time series data, or pretty much anything you care to put in a matrix with rows and named columns.\n",
    "\n",
    "It contains two primary data structures, the `Series` (1-dimensional) and the `DataFrame` (2-dimensional) as well as a host of convenience methods for loading and plotting data.\n",
    "\n",
    "The main thing that makes pandas pandas is that all data is *intrinsically aligned*. That means each data structure, `DataFrame` or `Series` has something called an **Index** that links data values with a label. That link will always be there (unless you explicitly break or change it) and it's what allows pandas to quickly and efficiently \"do the right thing\" when working with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The canonical way to import pandas:\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Series Object\n",
    "\n",
    "A `Series` is a one-dimensional array of indexed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.1, 0.2, 0.3, 0.4])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series` wraps a 1-d `ndarray` from numpy and an `Index` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This particular index type, the `RangeIndex`, lets us use the\n",
    "# same square-bracket notation as a `ndarray` to access elements:\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or even a slice:\n",
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to use this auto-generated list of integers as the index though. Index values can be specified manually and don't even have to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.1, 0.2, 0.3, 0.4], index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item access works just like before, with square brackets, \n",
    "# even though the index values are strings\n",
    "data['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slices still work! But note the last element is included this time.\n",
    "# This is the default behavior for indexes.\n",
    "data['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could create a non-sequential integer index:\n",
    "data = pd.Series([0.1, 0.2, 0.3, 0.4], index=[5, 8, 2, 1])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why?\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the critical difference between numpy arrays, which are always ordered sequentially and have an implicit integer index, and `Series` objects, which have an index that maps *labels* to *values*.\n",
    "\n",
    "`Series` are in fact a cross between a numpy array and a python dictionary. You can think of them as a dictionary with *typed* keys and *typed* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths_dict = {\n",
    "    'Erie': 64,\n",
    "    'Huron': 229,\n",
    "    'Michigan': 281,\n",
    "    'Ontario': 244,\n",
    "    'Superior': 406,\n",
    "}\n",
    "max_depths = pd.Series(max_depths_dict)\n",
    "max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squint and it looks like a dictionary!\n",
    "max_depths['Michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths_dict['Michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the index in this case was constructed automatically\n",
    "# from the dictionary keys.\n",
    "max_depths.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of an `Index` as an *immutable*, n-dimensional array. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DataFrame Object\n",
    "\n",
    "Much like the `Series` is a one-dimensional array of indexed data, a `DataFrame` is a two-dimensional array of indexed data.\n",
    "\n",
    "You can think of a `DataFrame` as a sequence of `Series` objects all sharing the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_depths_dict = {\n",
    "    'Erie': 19,\n",
    "    'Huron': 59,\n",
    "    'Michigan': 85,\n",
    "    'Ontario': 86,\n",
    "    'Superior': 149,\n",
    "}\n",
    "\n",
    "avg_depths = pd.Series(avg_depths_dict)\n",
    "\n",
    "lakes = pd.DataFrame({'Max Depth (m)': max_depths, 'Avg Depth (m)': avg_depths})\n",
    "lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like the `Series`, a `DataFrame` has an `index` property\n",
    "lakes.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a `values` property that exposes the underlying `ndarray`\n",
    "lakes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And unlike the Series, the DataFrame has a `columns` property\n",
    "lakes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the shape of a dataframe, just like a numpy ndarray\n",
    "lakes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do dictionary-style lookups into the dataframe by column name\n",
    "# to get a single Series:\n",
    "lakes['Max Depth (m)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select more than one column put a list of column names inside the dictionary-style square brackets:\n",
    "lakes[['Max Depth (m)','Avg Depth (m)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns\n",
    "\n",
    "Once we have a `DataFrame`, creating new columns is done through simple assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_area = pd.Series({\n",
    "    'Superior': 82097,\n",
    "    'Michigan': 57753,\n",
    "    'Huron': 59565,\n",
    "    'Erie': 25655,\n",
    "    'Ontario': 19009,\n",
    "})\n",
    "\n",
    "lakes['Surface Area (sq km)'] = surface_area\n",
    "lakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the index values allowed pandas to \"align\" the new data with the existing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to create new columns from existing columns. Say for example we wanted a column to track the difference between the avg depth and max depth. We'll call this the \"depth delta\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes['Depth Delta'] = lakes['Max Depth (m)'] - lakes['Avg Depth (m)']\n",
    "lakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Indexing and Selection\n",
    "\n",
    "Now that we can load data into pandas objects, we need to be able to access it. Pandas offers a variety of methods for accessing the data we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, both `Series` and `DataFrame` objects support dictionary-style access with square brackets. Think of index label values as dictionary keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We saw this above -- access a series like a dictionary to get a single value.\n",
    "avg_depths['Michigan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame dictionary-style access returns the Series with that column index label:\n",
    "lakes['Avg Depth (m)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also borrows array-style access from numpy. Namely, masking and \"fancy indexing\" work like in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a boolean mask to select just the items we want:\n",
    "avg_depths[avg_depths > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fancy indexing with an array of index labels:\n",
    "avg_depths[['Erie', 'Ontario']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a potential problem with non-sequential integer indexes:\n",
    "data_implicit = pd.Series([100, 200, 300, 400])\n",
    "data_explicit = pd.Series([100, 200, 300, 400], index=[4, 9, 8, 1])\n",
    "print(\"data_implicit[1] = {}\\ndata_explicit[1] = {}\".format(\n",
    "    data_implicit[1],\n",
    "    data_explicit[1]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle this potential confusion between label-based and position-based access and make data access easier in general, pandas provides three \"indexers\": `Series` and `DataFrame` attributes that expose differents ways to access the data.\n",
    "\n",
    "- `iloc`: always integer position-based\n",
    "- `loc`: always label-based\n",
    "- `ix`: primarily label-based, falls back to position-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_explicit.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_implicit.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_explicit.loc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use slices to select more than one value as well. Here, get all values after the first one:\n",
    "data_implicit.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix is useful with DataFrames and allows you to mix label and position-based\n",
    "lakes.ix[0, ['Avg Depth (m)', 'Max Depth (m)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop quiz! Let's get all rows of the lakes dataframe except the last one:\n",
    "lakes.iloc[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the first two rows and first two columns only?\n",
    "lakes.iloc[:2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes.loc['Erie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` accepts the following types of inputs:\n",
    "\n",
    "- a single label (as above)\n",
    "- a list or array of labels, e.g. ['a', 'b', 'c']\n",
    "- a slice object with labels e.g. 'a':'c' (note that contrary to usual python slices, both the start and the stop are included!)\n",
    "- A boolean array\n",
    "- A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)\n",
    "\n",
    "`loc` and `iloc` also take an optional second parameter, the list of column names to return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes.loc[['Michigan', 'Superior'], ['Max Depth (m)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to assign to the values at the locations you specify with the `iloc`, `loc`, or `ix` indexers! They aren't read-only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 10, (3, 3)), columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the value 100 to the 0,B and 1,B.\n",
    "# Remember with label-based access, which `loc` uses, the high end of the slice is *included*.\n",
    "df.loc[:1, 'B'] = 100\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Data\n",
    "\n",
    "While you can manipulate and operate on your data in any way you can dream up, pandas does provide basic descriptive statistics and sorting functionality for you. I **highly** recommend reading the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/api.html#computations-descriptive-stats) to see what methods are available and save yourself some work!\n",
    "\n",
    "The `describe` method is very useful with numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get the highest value for a given Series with `max`:\n",
    "max_depths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what if we wanted the top 2? `sort_values` is the answer:\n",
    "max_depths.sort_values(ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is so common that there is actually a shortcut for it:\n",
    "max_depths.nlargest(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which naturally works on DataFrames as well:\n",
    "lakes.nlargest(2, 'Avg Depth (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Pandas provides a bunch of functions for reading data from a variety of sources, including CSV, Excel files, SQL databases, HDF5, even your computer's clipboard! The always-comprehensive pandas documentation has more info here: [https://pandas.pydata.org/pandas-docs/stable/io.html](https://pandas.pydata.org/pandas-docs/stable/io.html).\n",
    "\n",
    "Let's read a local CSV dataset into a dataframe using the `read_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Speed_Camera_Violations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular `DataFrame` contains speed camera violation data provided by the city of Chicago. This dataset is available at [https://catalog.data.gov/dataset/speed-camera-violations-997eb](https://catalog.data.gov/dataset/speed-camera-violations-997eb).\n",
    "\n",
    "Let's start inspecting it by using the `head` method to look at the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data is loaded from an external source, pandas will try to guess the datatype for each column. Let's see how it did:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({col: df[col].dtype for col in df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types\n",
    "\n",
    "Much of pandas functionality depends on the data types of the `Series` it's working with. For instance we can get summary measures and do numpy-like parallel operations on numeric types (`int64`, `float64`), or do date-based arithmetic with `date` series.\n",
    "\n",
    "Notice above that the data type of the `VIOLATION DATE` column is \"object\", which, just like in numpy, means it is a generic type that isn't very useful. Let's turn those date strings into actual date objects, which are much better to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a Series, pd.to_datetime returns a new Series with the string dates parsed as actual dates.\n",
    "# We can then directly assign that Series back to the original column in our dataframe and pandas' magical Index\n",
    "# functionality will make it all line up properly.\n",
    "df[\"VIOLATION DATE\"] = pd.to_datetime(df[\"VIOLATION DATE\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "df[\"VIOLATION DATE\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Now that we have a date column, we can do things like filter to only look at violations in 2015.\n",
    "\n",
    "To do this, we'll create a \"filter\", essentially a boolean expression that works just like a mask or \"fancy indexing\" expression in numpy, and apply that filter to our dataframe to get just the rows we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# note the extra parentheses below, these are necessary when creating a boolean filter expression with\n",
    "# multiple comparisons like this\n",
    "date_filter = ((df[\"VIOLATION DATE\"] >= datetime.date(2015,1,1)) & (df[\"VIOLATION DATE\"] < datetime.date(2016,1,1)))\n",
    "\n",
    "# date_filter now contains a series of true/false values that we can use to extract just the values we are interested in\n",
    "# by putting it in square brackets after the dataframe variable.\n",
    "print(date_filter.head())\n",
    "print()\n",
    "print(date_filter.tail())\n",
    "\n",
    "df_2015 = df[date_filter]\n",
    "\n",
    "df_2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of filtering works for any kind of data type, provided you take care to make sure pandas is using the right data types for your data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that many of the rows in this dataframe are missing lat/lon data. Pandas uses the \"NaN\" placeholder for missing data and offers some methods for dealing with it.\n",
    "\n",
    "Both `Series` and `DataFrame` objects have `fillna` method that will replace missing data with a specified value.\n",
    "\n",
    "In thise case however we may want to just drop those records that have missing data entirely:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nans = df.dropna(axis=0, how=\"any\")\n",
    "df_no_nans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
